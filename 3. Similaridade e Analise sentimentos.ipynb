{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Aula 3 CDO1T2 (Ana Carolina ).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8727ffa824824a66b8c54256496df7e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_06591da91b954a63be1e4a67d82f0468",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_322165a801944cc8a517f237b26b86f0",
              "IPY_MODEL_6cd698bda02d4677bd1764e094bd7801",
              "IPY_MODEL_90a85489671341f19f3fdcd32fdd2a0e"
            ]
          }
        },
        "06591da91b954a63be1e4a67d82f0468": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "322165a801944cc8a517f237b26b86f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_59c3b7ddd77648bc987d9ded53270f79",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_37c7921415e84f9aa94a8b286b1fc8bc"
          }
        },
        "6cd698bda02d4677bd1764e094bd7801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2dcaad497bf747f2b08637d3bd7c071e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 49459,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 49459,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d9702dc575424774beecce09bf813292"
          }
        },
        "90a85489671341f19f3fdcd32fdd2a0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c1051cb5883f415b8f1e19277db60528",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 49459/49459 [01:00&lt;00:00, 821.21it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c59148c93a274995ba9e3e28eb14c22d"
          }
        },
        "59c3b7ddd77648bc987d9ded53270f79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "37c7921415e84f9aa94a8b286b1fc8bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2dcaad497bf747f2b08637d3bd7c071e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d9702dc575424774beecce09bf813292": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c1051cb5883f415b8f1e19277db60528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c59148c93a274995ba9e3e28eb14c22d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "86ba03eb85b440028bdc1b304f786aab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_01d4b63812cd4a61beca2d14a92dbd1c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b727db06d87d4d888472043d4df643d3",
              "IPY_MODEL_9d3fb1f39cac4452837eaf518bc8a9c3",
              "IPY_MODEL_a5b40eab76c647fabfba370778bc26c9"
            ]
          }
        },
        "01d4b63812cd4a61beca2d14a92dbd1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b727db06d87d4d888472043d4df643d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aef04d4433c1414ab9002251798eda0b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d3268643c19e4975bce5419f1cecf51d"
          }
        },
        "9d3fb1f39cac4452837eaf518bc8a9c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_58e9243afc0a442db2f9a653a57b67fe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 49459,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 49459,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8fb25a5009884a3b94e75884c9db7175"
          }
        },
        "a5b40eab76c647fabfba370778bc26c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2873c8c2cef648209bca9acf4ee95859",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 49459/49459 [00:26&lt;00:00, 2153.93it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cfd36b35d34f46139fb60be799239fd2"
          }
        },
        "aef04d4433c1414ab9002251798eda0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d3268643c19e4975bce5419f1cecf51d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "58e9243afc0a442db2f9a653a57b67fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8fb25a5009884a3b94e75884c9db7175": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2873c8c2cef648209bca9acf4ee95859": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cfd36b35d34f46139fb60be799239fd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-Mgum7LZZmf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e31d287-97a7-4fa3-c247-dd65397b2b78"
      },
      "source": [
        "!pip install afinn\n",
        "!python -m textblob.download_corpora\n",
        "!pip install -U textblob\n",
        "!pip install vaderSentiment\n",
        "!pip install pyemd\n",
        "!pip install unidecode"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting afinn\n",
            "  Downloading afinn-0.1.tar.gz (52 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▎                         | 10 kB 18.8 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 20 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 30 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 40 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 51 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 52 kB 826 kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: afinn\n",
            "  Building wheel for afinn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for afinn: filename=afinn-0.1-py3-none-any.whl size=53447 sha256=a4640a3ba8c1032ac7908edb4cdad37470797245491a07f82f07b6e4f7a3ac2c\n",
            "  Stored in directory: /root/.cache/pip/wheels/9d/16/3a/9f0953027434eab5dadf3f33ab3298fa95afa8292fcf7aba75\n",
            "Successfully built afinn\n",
            "Installing collected packages: afinn\n",
            "Successfully installed afinn-0.1\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (0.15.3)\n",
            "Collecting textblob\n",
            "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 3.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (1.15.0)\n",
            "Installing collected packages: textblob\n",
            "  Attempting uninstall: textblob\n",
            "    Found existing installation: textblob 0.15.3\n",
            "    Uninstalling textblob-0.15.3:\n",
            "      Successfully uninstalled textblob-0.15.3\n",
            "Successfully installed textblob-0.17.1\n",
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Installing collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n",
            "Requirement already satisfied: pyemd in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from pyemd) (1.21.5)\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.3-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 4.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR9dcTSYZZml",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6e20318-cc1e-4022-8883-d302c099468c"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from unidecode import unidecode\n",
        "import pandas as pd\n",
        "import bz2\n",
        "import gensim\n",
        "import warnings\n",
        "import numpy as np\n",
        "from gensim.models import word2vec\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from scipy.spatial import distance\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm._tqdm_notebook import tqdm_notebook\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "tqdm_notebook.pandas()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.*` instead of `tqdm._tqdm_notebook.*`\n",
            "  app.launch_new_instance()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjOYV0cfZZmq"
      },
      "source": [
        "# Carregando os embeddings\n",
        "\n",
        "Aqui vamos utilizar os embeddings para realizar as seguintes atividades:\n",
        "\n",
        "- análise de simlaridade\n",
        "- classificação de documentos\n",
        "\n",
        "<b> Carregue os embeddings treinados, como vimos na Aula 2. É o mesmo arquivo que iremos utilizar</b>\n",
        "\n",
        "Link: https://drive.google.com/open?id=1zI8pGfbUHuU_0wY_FV4tD6w6ZCUJTQbh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqMDMgrBZZmr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08eb63ef-d146-45c2-ccc4-d9676cb3e0f7"
      },
      "source": [
        "#opção 1 -> montar o drive no colab e acessar o arquivo de embedding do drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#opção 2 -> fazer download e fazer upload por aqui\n",
        "#from google.colab import files\n",
        "#uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# carregar\n",
        "##na variável path coloque o caminho do embedding baixado:\n",
        "path = \"/content/drive/MyDrive/ptwiki_20180420_100d.txt.bz2\"\n",
        "word_vectors = gensim.models.KeyedVectors.load_word2vec_format(path, binary=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfwMi1R4OnG6",
        "outputId": "0f1add92-f219-4f6a-b5c3-dbe26bc33ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2min 44s, sys: 1.1 s, total: 2min 45s\n",
            "Wall time: 2min 48s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqZJuktuZZmv"
      },
      "source": [
        "# Similaridade de Documentos\n",
        "\n",
        "Para realizar a similaridade entre documentos, utilize as frases abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-YjfkcTZZmw"
      },
      "source": [
        "frase1 = \"Excelente produto chegou antes do prazo indico e recomendo produto bom pois já testei e foi mais que aprovado\" \n",
        "frase2 = \"SUPER RECOMENDO, PREÇO, QUALIDADE #BRASTEMP, EFICIÊNCIA NA ENTREGA, E FACILIDADE DE PAGAMENTO. MUITO BOM!!!\"\n",
        "frase3 = \"A tampa do fogão veio com problemas com o pino de encaixe solto e precisa de reparos\"\n",
        "frase4 = \"Fogão ótimo!\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNGfjS5RZZm1"
      },
      "source": [
        "## Distância de Jaccard\n",
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "1) Faça um método que calcule a similaridade de Jaccard e aplique para os seguintes pares de frases:\n",
        "\n",
        "- Frase1 e Frase2\n",
        "- Frase1 e Frase3\n",
        "- Frase2 e Frase3\n",
        "- Frase1 e Frase4\n",
        "\n",
        "Observação: lembrando que você precisa aplicar um pre-processamento nessas frases antes de aplicar o método.\n",
        "Faça:\n",
        "\n",
        "- Lower\n",
        "- Remoção StopWords\n",
        "- Remoção Pontuação\n",
        "- Tokenização"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn2YYL7bZZm2"
      },
      "source": [
        "def pre_processamento_texto(corpus):\n",
        "  import nltk\n",
        "  nltk.download('stopwords')\n",
        "  print('Document')\n",
        "  print(\"#Tokenização\")\n",
        "  corpus_alt = re.findall(r\"\\w+(?:'\\w+)?|[^\\w\\s]\", corpus)\n",
        "  #lowcase\n",
        "  corpus_alt = [ t.lower() for t in corpus_alt  ]\n",
        "  print('remove stopwords')\n",
        "  portuguse_stops = stopwords.words('portuguese')\n",
        "  corpus_alt = [t for  t in corpus_alt if t not in portuguse_stops]\n",
        "  print('remove numeros')\n",
        "  corpus_alt = [re.sub(r'\\d','',t) for t in  corpus_alt]\n",
        "  print('remove pontuação')\n",
        "  corpus_alt = [t for  t in corpus_alt if t not in string.punctuation]\n",
        "  #print('remove acentos')\n",
        "  #corpus_alt = [unidecode(t) for t in  corpus_alt]\n",
        "  return corpus_alt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frase_1_pre_processamento=pre_processamento_texto(frase1)\n",
        "frase_2_pre_processamento=pre_processamento_texto(frase2)\n",
        "frase_3_pre_processamento=pre_processamento_texto(frase3)\n",
        "frase_4_pre_processamento=pre_processamento_texto(frase4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5AuGQCsZ22q",
        "outputId": "55b07c36-2207-4742-96ba-6d6225e3e273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Document\n",
            "#Tokenização\n",
            "remove stopwords\n",
            "remove numeros\n",
            "remove pontuação\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Document\n",
            "#Tokenização\n",
            "remove stopwords\n",
            "remove numeros\n",
            "remove pontuação\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Document\n",
            "#Tokenização\n",
            "remove stopwords\n",
            "remove numeros\n",
            "remove pontuação\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Document\n",
            "#Tokenização\n",
            "remove stopwords\n",
            "remove numeros\n",
            "remove pontuação\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(frase_1_pre_processamento).intersection(set(frase_2_pre_processamento)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWhnFBn0anqR",
        "outputId": "d5f83b24-0897-45d2-e541-522cd6b76931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(frase_1_pre_processamento).union(set(frase_2_pre_processamento)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_n29kBGboVq",
        "outputId": "0077ab36-319b-4cb1-b20f-aa0317911e31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def jaccard(f1,f2):\n",
        "  return len(set(f1).intersection(set(f2)))/len(set(f1).union(set(f2)))"
      ],
      "metadata": {
        "id": "G4luOG23cDdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jaccard(frase_1_pre_processamento,frase_2_pre_processamento)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Q-YT9dKcZjb",
        "outputId": "5019ea25-c5ec-4c6e-8cbe-5e118fd4ac3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.10526315789473684"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jaccard(frase_1_pre_processamento,frase_3_pre_processamento)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y32xAwXHchGa",
        "outputId": "8f230187-d0e3-4f41-bd6d-d4df80befd37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jaccard(frase_2_pre_processamento,frase_3_pre_processamento)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYGv3JWicjXa",
        "outputId": "806623fe-74f4-4a7e-fce7-4f93ebdca5a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jaccard(frase_1_pre_processamento,frase_4_pre_processamento)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLGPgAImcjeY",
        "outputId": "645815d7-6a61-403d-8056-6f8610f58b6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke1PVggcZZm8"
      },
      "source": [
        "<b> Atividade </b>\n",
        "\n",
        "2) Qual par de frase teve maior simlaridade? E qual teve menor? Este resultado faz sentido? Explique."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As frases 1 e 2. As demais tiveram similaridade zero. Não, as frases são utilizadas em contexto parecido, com semântica parecida. O jaccard tem limitações"
      ],
      "metadata": {
        "id": "jZJFDkCodMXB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND3usAELZZm-"
      },
      "source": [
        "## Distância de Cosseno\n",
        "\n",
        "Aqui iremos calcular a distância do cosseno utilizando duas formas, que aprendemos na aula passada, para representar o texto.\n",
        "\n",
        "- Bag of Words (BOW) \n",
        "- Embedding\n",
        "\n",
        "Observação:\n",
        "\n",
        "Existem duas formas de trabalhar com o cosseno:\n",
        "\n",
        "<b> Distância </b>: quanto menor mais perto estão as frases.\n",
        "<b> Similaridade </b>: quanto maior mais perto estão as frases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_Qw93ZLZZm-"
      },
      "source": [
        "### BOW - Distância do cosseno\n",
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "3) Calcule a distância do cosseno utilizando a representação CountVectorizer e aplique para os seguintes pares de frases:\n",
        "\n",
        "- Frase1 e Frase2\n",
        "- Frase1 e Frase3\n",
        "- Frase2 e Frase3\n",
        "- Frase1 e Frase4\n",
        "\n",
        "Observação: no CountVectorizer utilizem as frases já pre-processadas da atividade anterior. Mas para aplicá-las no fit_transform, cada frase deve ser um string (sem estar tokenizada) dentro de uma lista.\n",
        "\n",
        "```python\n",
        "#exemplo\n",
        "distance.cosine(frase1, frase2)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CzqpPPGZZm_"
      },
      "source": [
        "vect_bag = CountVectorizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_bag = vect_bag.fit_transform([' '.join(frase_1_pre_processamento),\\\n",
        "                                  ' '.join(frase_2_pre_processamento),\\\n",
        "                                  ' '.join(frase_3_pre_processamento),\\\n",
        "                                  ' '.join(frase_4_pre_processamento)])"
      ],
      "metadata": {
        "id": "7Hxo1rYSiGDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_bag[0].todense()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odC-P4KRisrD",
        "outputId": "e57ac02b-d8e0-4e1a-8c61-ef0426d911b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 2, 0,\n",
              "         1, 0, 0, 0, 0, 1, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frase1_bow = docs_bag[0].todense()\n",
        "frase2_bow = docs_bag[1].todense()\n",
        "frase3_bow = docs_bag[2].todense()\n",
        "frase4_bow = docs_bag[3].todense()"
      ],
      "metadata": {
        "id": "B_dWkWtaiGKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(distance.cosine(frase1_bow, frase2_bow))\n",
        "print(distance.cosine(frase1_bow, frase3_bow))\n",
        "print(distance.cosine(frase2_bow, frase3_bow))\n",
        "print(distance.cosine(frase1_bow, frase4_bow))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohLTR7iHiGQc",
        "outputId": "72347eee-6679-45ef-a088-202db33ef7e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8309691490542968\n",
            "1.0\n",
            "1.0\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3G4ckzlZZnN"
      },
      "source": [
        "### Embedding - Distância do cosseno\n",
        "\n",
        "Para calcular o embedding de cada uma das frases, utilize o modelo carregado inicialmente. \n",
        "\n",
        "Cada palavra tem um vetor, para formar o embedding da frase tire a média de todos os vetores.\n",
        "\n",
        "Utilize as frases já pre-processadas\n",
        "\n",
        "<b> Atividade </b> \n",
        "\n",
        "4) Calcule a distância do cosseno utilizando a representação Embedding e aplique para os seguintes pares de frases:\n",
        "\n",
        "- Frase1 e Frase2\n",
        "- Frase1 e Frase3\n",
        "- Frase2 e Frase3\n",
        "- Frase1 e Frase4\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRO8RnLgZZnO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ad73db9-22e7-491b-e7e0-5f0d2d39e871"
      },
      "source": [
        "word_vectors['fogão']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.3057, -0.076 ,  0.6269, -0.2146, -0.4847, -0.1121, -0.132 ,\n",
              "        0.4016, -0.2735,  0.8309,  0.4079, -0.1401,  0.0916, -0.1943,\n",
              "       -0.1852, -0.1271,  0.124 , -0.2686, -0.0234, -0.0617, -0.5043,\n",
              "       -0.0357, -0.3085, -0.1748,  0.0502,  0.2168, -0.5501, -0.4325,\n",
              "       -0.3013, -0.3772,  0.8357,  0.0859,  0.6692,  1.1012, -0.1948,\n",
              "       -0.4732, -0.1394, -0.4083,  0.6847,  0.0633, -0.1836, -0.1726,\n",
              "       -0.4396, -0.0672,  0.5016,  0.0675, -0.2919, -0.0864, -0.6857,\n",
              "       -0.4937,  0.8398, -0.2043, -0.4746,  0.0547,  0.041 ,  0.0535,\n",
              "       -0.0022, -0.8022,  0.5122,  0.3449,  0.7115, -0.8373, -0.2469,\n",
              "       -0.1739,  0.0985,  0.4376, -0.0918, -0.0374,  0.0578,  0.2694,\n",
              "       -0.0275, -0.2675, -0.5567, -0.3373, -0.527 , -0.0812,  0.1699,\n",
              "       -0.3703, -0.6308, -0.6002,  0.4416, -0.8358, -0.174 ,  0.0079,\n",
              "        0.1091,  0.2028,  0.2061, -0.0552, -0.0064,  0.6256,  0.8936,\n",
              "       -0.313 , -0.365 , -0.4255, -0.5043,  0.4329,  0.6975, -0.2431,\n",
              "        0.0726, -0.3888], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors['ótimo']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZD1cGnmy5WM",
        "outputId": "8f5c0a72-f055-4202-bd81-358d53513288"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.07  ,  0.328 , -0.4575,  0.0816, -0.5353, -0.2608,  0.18  ,\n",
              "        0.3187, -0.4454,  0.3796,  0.4828, -0.225 , -0.3291,  0.1281,\n",
              "       -0.059 ,  0.5279,  0.2425, -0.8551,  0.2208,  0.2369, -0.1975,\n",
              "        0.3723, -0.126 , -0.0727, -0.5586,  0.0239, -0.1535, -0.7805,\n",
              "        0.1168,  0.1669, -0.0682,  0.184 ,  0.5678,  0.3104, -0.1147,\n",
              "       -0.5562,  0.0407, -0.064 ,  0.0974,  0.1565,  0.5655, -0.0801,\n",
              "       -0.3852,  0.322 ,  0.0552, -0.0832, -0.0416,  0.2012, -0.9991,\n",
              "        0.0058,  0.7823,  0.3251,  0.0067,  0.1056,  0.6211, -0.4179,\n",
              "       -0.0079, -0.5724,  0.1751,  0.3493,  0.3302, -0.5236, -0.1005,\n",
              "        0.4321,  0.4189, -0.0374, -0.2467,  0.1282,  0.4268,  0.0969,\n",
              "       -0.3075,  0.5029, -0.2893, -0.2478, -0.0493,  0.4143, -0.2963,\n",
              "        0.279 ,  0.005 ,  0.2045, -0.158 ,  0.2136, -0.5662, -0.1397,\n",
              "       -0.6357, -0.3585, -0.0588, -0.4662,  0.2503, -0.678 ,  0.8295,\n",
              "       -0.5559, -0.2378, -0.1326, -0.0595, -0.0442, -0.0446, -0.1188,\n",
              "       -0.7148, -0.155 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(np.array([word_vectors[palavra] for palavra in frase_4_pre_processamento]),axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yg0Dh9qazQST",
        "outputId": "abcb76bc-f913-4ffd-9f77-2ec3e3d8022c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.18785   ,  0.126     ,  0.0847    , -0.06649999, -0.51      ,\n",
              "       -0.18645   ,  0.024     ,  0.36014998, -0.35944998,  0.60525   ,\n",
              "        0.44535   , -0.18255   , -0.11875001, -0.0331    , -0.1221    ,\n",
              "        0.2004    ,  0.18325001, -0.56184995,  0.0987    ,  0.0876    ,\n",
              "       -0.3509    ,  0.1683    , -0.21724999, -0.12375   , -0.2542    ,\n",
              "        0.12035   , -0.35180002, -0.6065    , -0.09224999, -0.10515001,\n",
              "        0.38375   ,  0.13495   ,  0.6185    ,  0.7058    , -0.15475   ,\n",
              "       -0.5147    , -0.04935   , -0.23615001,  0.39105   ,  0.1099    ,\n",
              "        0.19095   , -0.12635   , -0.4124    ,  0.1274    ,  0.2784    ,\n",
              "       -0.00785   , -0.16675   ,  0.0574    , -0.8424    , -0.24395   ,\n",
              "        0.81105   ,  0.0604    , -0.23394999,  0.08015   ,  0.33105   ,\n",
              "       -0.1822    , -0.00505   , -0.68729997,  0.34364998,  0.34710002,\n",
              "        0.52085   , -0.68044996, -0.1737    ,  0.1291    ,  0.2587    ,\n",
              "        0.20009999, -0.16925   ,  0.0454    ,  0.2423    ,  0.18315   ,\n",
              "       -0.1675    ,  0.1177    , -0.42299998, -0.29255   , -0.28815   ,\n",
              "        0.16655   , -0.0632    , -0.04564999, -0.3129    , -0.19784999,\n",
              "        0.14179999, -0.3111    , -0.37010002, -0.0659    , -0.2633    ,\n",
              "       -0.07785   ,  0.07365   , -0.2607    ,  0.12194999, -0.0262    ,\n",
              "        0.86155   , -0.43444997, -0.3014    , -0.27905   , -0.2819    ,\n",
              "        0.19435   ,  0.32645   , -0.18095   , -0.3211    , -0.2719    ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calcula_embedding(frase):\n",
        "  return np.mean(np.array([word_vectors[palavra] for palavra in frase]),axis=0)"
      ],
      "metadata": {
        "id": "Xy_abRgn4N2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frase1_emb = calcula_embedding(frase_1_pre_processamento)\n",
        "frase2_emb = calcula_embedding(frase_2_pre_processamento)\n",
        "frase3_emb = calcula_embedding(frase_3_pre_processamento)\n",
        "frase4_emb = calcula_embedding(frase_4_pre_processamento)"
      ],
      "metadata": {
        "id": "auEC-Zx44d_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(distance.cosine(frase1_emb, frase2_emb))\n",
        "print(distance.cosine(frase1_emb, frase3_emb))\n",
        "print(distance.cosine(frase2_emb, frase3_emb))\n",
        "print(distance.cosine(frase1_emb, frase4_emb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnCPeERy5Vqd",
        "outputId": "d572dd9f-9b58-4850-8aed-a4057f56ce99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.16096973419189453\n",
            "0.2234203815460205\n",
            "0.2526938319206238\n",
            "0.29043054580688477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgZWHiGSZZnT"
      },
      "source": [
        "<b>Atividade </b>\n",
        "\n",
        "5) Qual diferença entre as representações do exercício 3 e 4? Qual faz mais sentido? Explique."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A distância de similaridade de cosseno foi cálculada com bag of words e outra com embedding. A cálculada com embedding pois representa melhor as frases com contexto semelhante."
      ],
      "metadata": {
        "id": "iKI4IWxD6TsG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hx5acLVhZZne"
      },
      "source": [
        "## WMD\n",
        "\n",
        "O WMD já está incorporado ao Word2Vec\n",
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "6) Calcule a distância WMD e aplique para os seguintes pares de frases:\n",
        "\n",
        "- Frase1 e Frase2\n",
        "- Frase1 e Frase3\n",
        "- Frase2 e Frase3\n",
        "- Frase1 e Frase4\n",
        "\n",
        "Observação: use a variável já tokenizada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0881q7vZZne",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ebf5adc-7561-4818-8e04-3c66010996c2"
      },
      "source": [
        "print(word_vectors.wmdistance(frase_1_pre_processamento,frase_2_pre_processamento))\n",
        "print(word_vectors.wmdistance(frase_1_pre_processamento,frase_3_pre_processamento))\n",
        "print(word_vectors.wmdistance(frase_2_pre_processamento,frase_3_pre_processamento))\n",
        "print(word_vectors.wmdistance(frase_1_pre_processamento,frase_4_pre_processamento))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.0725697404938526\n",
            "3.759219170455064\n",
            "3.9048993635316385\n",
            "3.851623338336251\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsIENn25ZZni"
      },
      "source": [
        "<b> Atividade </b>\n",
        "\n",
        "7) Qual par de frase teve maior distância? E qual teve menor? Este resultado faz sentido? Explique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhC4OvGWZZnj"
      },
      "source": [
        "A frase 2 e 3. A frase 1 com a 2. Sim. As frases mais parecidas tem a menor distância WMD."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXHGivtDZZnk"
      },
      "source": [
        "# Classificação de Documentos\n",
        "\n",
        "A clssificação de documentos é muito útil em vários aspectos. Um dos tipos de classificação de texto é a análise de sentimentos.\n",
        "\n",
        "A fim de ilustrar a classificação de documentos iremos criar um modelo para classificar uma frase como positiva ou negativa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhCOoEn7ZZno"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "8) Carregue o dataset com o pandas e depois dê o head no dataframe.\n",
        "\n",
        "\n",
        "Link download: https://drive.google.com/open?id=15azJWdEEPGsXQGiDmEOseTBJcquWvBQc\n",
        "\n",
        "<b> Este dataset é sobre revisões de filmes do IMDB. </b>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# carregar\n",
        "##na variável path coloque o caminho do embedding baixado:\n",
        "path_imdb = \"/content/drive/MyDrive/Trabalhos - Pós/imdb-reviews-pt-br.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_Q3Hu7sRpl8",
        "outputId": "d1b81e1c-99d4-437c-c540-788bfc282543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 19.6 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJYAOZecZZnv"
      },
      "source": [
        "df= pd.read_csv(path_imdb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5oyBmGHDm5yu",
        "outputId": "e173585b-f355-4eae-aa5e-2c770e6ccd41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-75b91f3d-946e-475b-beb8-214c5a3edc9f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text_en</th>\n",
              "      <th>text_pt</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
              "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>This is an example of why the majority of acti...</td>\n",
              "      <td>Este é um exemplo do motivo pelo qual a maiori...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>First of all I hate those moronic rappers, who...</td>\n",
              "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Not even the Beatles could write songs everyon...</td>\n",
              "      <td>Nem mesmo os Beatles puderam escrever músicas ...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Brass pictures movies is not a fitting word fo...</td>\n",
              "      <td>Filmes de fotos de latão não é uma palavra apr...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75b91f3d-946e-475b-beb8-214c5a3edc9f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-75b91f3d-946e-475b-beb8-214c5a3edc9f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-75b91f3d-946e-475b-beb8-214c5a3edc9f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   id                                            text_en  \\\n",
              "0   1  Once again Mr. Costner has dragged out a movie...   \n",
              "1   2  This is an example of why the majority of acti...   \n",
              "2   3  First of all I hate those moronic rappers, who...   \n",
              "3   4  Not even the Beatles could write songs everyon...   \n",
              "4   5  Brass pictures movies is not a fitting word fo...   \n",
              "\n",
              "                                             text_pt sentiment  \n",
              "0  Mais uma vez, o Sr. Costner arrumou um filme p...       neg  \n",
              "1  Este é um exemplo do motivo pelo qual a maiori...       neg  \n",
              "2  Primeiro de tudo eu odeio esses raps imbecis, ...       neg  \n",
              "3  Nem mesmo os Beatles puderam escrever músicas ...       neg  \n",
              "4  Filmes de fotos de latão não é uma palavra apr...       neg  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCKr5KPMZZnz"
      },
      "source": [
        "## Representação dos dados\n",
        "\n",
        "O sentimento positivo e negativo iremos binarizar cada um deles. Seja 1 positivo e 0 negativo.\n",
        "\n",
        "Iremos representar o texto de duas formas:\n",
        "\n",
        "- Bag of Words (BOW)\n",
        "- Embedding\n",
        "\n",
        "Depois iremos comparar o resultado de cada um deles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POkSAiYMZZn0"
      },
      "source": [
        "### Representação Target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0mYbWgcZZn1"
      },
      "source": [
        "<b> Atividade </b>\n",
        "\n",
        "9) Faça a representação dos sentimentos. 1 positivo; 0 negativo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBkDjo4VZZn2"
      },
      "source": [
        "target = df['sentiment'].replace(['neg','pos'],[0,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8VgGgUnZZn8"
      },
      "source": [
        "### Bag of Words (BOW)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xirBWWCzZZn-"
      },
      "source": [
        "<b> Atividade </b>\n",
        "\n",
        "10) Aplique o pré-processamento listado abaixo na coluna ``text_pt`` (crie uma nova coluna ```text_pt_sem_stopwords``` no dataframe para armazenar este dado processado):\n",
        "\n",
        "- Remova as stopwords do texto\n",
        "- Remova as pontuções\n",
        "- Mantenha o texto sem tokenização, ou seja uma string\n",
        "\n",
        "<b> Dica: </b> use o ```progress_apply``` para exibir a barra de progresso:\n",
        "\n",
        "```python\n",
        "from tqdm._tqdm_notebook import tqdm_notebook\n",
        "tqdm_notebook.pandas()\n",
        "df[\"colunas\"].progress_apply(lambda x: preprocessamento(x))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnJokm8VZZn-"
      },
      "source": [
        "def pre_processamento_texto(corpus):\n",
        "  import nltk\n",
        "  nltk.download('stopwords')\n",
        "  print('Document')\n",
        "  print(\"#Tokenização\")\n",
        "  corpus_alt = re.findall(r\"\\w+(?:'\\w+)?|[^\\w\\s]\", corpus)\n",
        "  #lowcase\n",
        "  corpus_alt = [ t.lower() for t in corpus_alt  ]\n",
        "  print('remove stopwords')\n",
        "  portuguse_stops = stopwords.words('portuguese')\n",
        "  corpus_alt = [t for  t in corpus_alt if t not in portuguse_stops]\n",
        "  print('remove numeros')\n",
        "  corpus_alt = [re.sub(r'\\d','',t) for t in  corpus_alt]\n",
        "  print('remove pontuação')\n",
        "  corpus_alt = [t for  t in corpus_alt if t not in string.punctuation]\n",
        "  #print('remove acentos')\n",
        "  #corpus_alt = [unidecode(t) for t in  corpus_alt]\n",
        "  corpus_alt = ' '.join(corpus_alt).lower()\n",
        "  return corpus_alt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_pt_LIMPO_BOW'] = df['text_pt'].progress_apply(pre_processamento_texto) "
      ],
      "metadata": {
        "id": "5nsiC2pGpJ_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_pt_LIMPO_BOW']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nVX-urxomub",
        "outputId": "c4838b2b-e857-4fce-90d6-d4cabb7b951b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        vez sr costner arrumou filme tempo necessário ...\n",
              "1        exemplo motivo maioria filmes ação mesmos gené...\n",
              "2        primeiro tudo odeio raps imbecis poderiam agir...\n",
              "3        beatles puderam escrever músicas todos gostass...\n",
              "4        filmes fotos latão palavra apropriada verdade ...\n",
              "                               ...                        \n",
              "49454    média votos baixa fato funcionário locadora ac...\n",
              "49455    enredo algumas reviravoltas infelizes inacredi...\n",
              "49456    espantado forma filme maioria outros média est...\n",
              "49457    christmas together realmente veio antes tempo ...\n",
              "49458    drama romântico classe trabalhadora diretor ma...\n",
              "Name: text_pt_LIMPO_BOW, Length: 49459, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TddT2Y6JZZoC"
      },
      "source": [
        "<b> Atividade </b>\n",
        "\n",
        "11) Aplique a representação do texto processado anteriormente com CountVectorizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axSZo69tZZoC"
      },
      "source": [
        "vect_bag = CountVectorizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_bag = vect_bag.fit_transform(df['text_pt_LIMPO_BOW'])"
      ],
      "metadata": {
        "id": "Tat0Rd16s02q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCx9q6P7tC4L",
        "outputId": "6c517387-d2e7-4647-de2f-5850a3f6ce79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49459, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_bag"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7WxywMmtKaK",
        "outputId": "e9d8684f-0a40-43ed-91da-f7b6ccb708a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<49459x127503 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 5030933 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mELsQ0tvZZoF"
      },
      "source": [
        "### Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSUe-Yr_ZZoG"
      },
      "source": [
        "<b> Atividade </b>\n",
        "\n",
        "12) Aplique o pré-processamento listado abaixo na coluna ``text_pt`` (crie uma nova coluna ```text_pt_sem_stopwords_token``` no dataframe para armazenar este dado processado):\n",
        "\n",
        "- Aplique lower\n",
        "- Remova as stopwords do texto\n",
        "- Remova as pontuções\n",
        "- Mantenha o texto com tokenização\n",
        "\n",
        "<b> Dica: </b> use o ```progress_apply``` para exibir a barra de progresso:\n",
        "\n",
        "```python\n",
        "from tqdm._tqdm_notebook import tqdm_notebook\n",
        "tqdm_notebook.pandas()\n",
        "df[\"colunas\"].progress_apply(lambda x: preprocessamento(x))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odeOuXqqGtuQ",
        "outputId": "ce3c6669-18f0-44f0-f493-b8df25c9375e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBJxB_SsZZoH"
      },
      "source": [
        "def pre_processamento_texto(corpus):\n",
        "  #print(\"#Tokenização\")\n",
        "  corpus_alt = re.findall(r\"\\w+(?:'\\w+)?|[^\\w\\s]\", corpus)\n",
        "  #lowcase\n",
        "  corpus_alt = [ t.lower() for t in corpus_alt  ]\n",
        "  #print('remove stopwords')\n",
        "  portuguse_stops = stopwords.words('portuguese')\n",
        "  corpus_alt = [t for  t in corpus_alt if t not in portuguse_stops]\n",
        "  #print('remove numeros')\n",
        "  corpus_alt = [re.sub(r'\\d','',t) for t in  corpus_alt]\n",
        "  #print('remove pontuação')\n",
        "  corpus_alt = [t for  t in corpus_alt if t not in string.punctuation]\n",
        "  return corpus_alt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_pt_LIMPO_EMB'] = df['text_pt'].progress_apply(lambda x: pre_processamento_texto(x)) "
      ],
      "metadata": {
        "id": "pYcaptaMtsWJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48,
          "referenced_widgets": [
            "8727ffa824824a66b8c54256496df7e4",
            "06591da91b954a63be1e4a67d82f0468",
            "322165a801944cc8a517f237b26b86f0",
            "6cd698bda02d4677bd1764e094bd7801",
            "90a85489671341f19f3fdcd32fdd2a0e",
            "59c3b7ddd77648bc987d9ded53270f79",
            "37c7921415e84f9aa94a8b286b1fc8bc",
            "2dcaad497bf747f2b08637d3bd7c071e",
            "d9702dc575424774beecce09bf813292",
            "c1051cb5883f415b8f1e19277db60528",
            "c59148c93a274995ba9e3e28eb14c22d"
          ]
        },
        "outputId": "10c9bb94-53df-4ad9-9039-22890811f224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8727ffa824824a66b8c54256496df7e4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/49459 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_pt_LIMPO_EMB']"
      ],
      "metadata": {
        "id": "9EWrplepvXrh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e81d570f-46bd-460a-aec7-e5775174750e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [vez, sr, costner, arrumou, filme, tempo, nece...\n",
              "1        [exemplo, motivo, maioria, filmes, ação, mesmo...\n",
              "2        [primeiro, tudo, odeio, raps, imbecis, poderia...\n",
              "3        [beatles, puderam, escrever, músicas, todos, g...\n",
              "4        [filmes, fotos, latão, palavra, apropriada, ve...\n",
              "                               ...                        \n",
              "49454    [média, votos, baixa, fato, funcionário, locad...\n",
              "49455    [enredo, algumas, reviravoltas, infelizes, ina...\n",
              "49456    [espantado, forma, filme, maioria, outros, méd...\n",
              "49457    [christmas, together, realmente, veio, antes, ...\n",
              "49458    [drama, romântico, classe, trabalhadora, diret...\n",
              "Name: text_pt_LIMPO_EMB, Length: 49459, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZPhMIrWZZoM"
      },
      "source": [
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "13) Aplique a representação do texto com Embeddings. Cada palavra tem um embedding, o embedding da frase é a média de todos embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4gg0S5NZZoM"
      },
      "source": [
        "def calcula_embedding(frase):\n",
        "  return np.mean(np.array([word_vectors[palavra] for palavra in frase if palavra in word_vectors.vocab]),axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_pt_LIMPO_EMB']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYSX1K_2emBV",
        "outputId": "a9fe8696-41ed-4f79-e9c0-18bc12766110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [vez, sr, costner, arrumou, filme, tempo, nece...\n",
              "1        [exemplo, motivo, maioria, filmes, ação, mesmo...\n",
              "2        [primeiro, tudo, odeio, raps, imbecis, poderia...\n",
              "3        [beatles, puderam, escrever, músicas, todos, g...\n",
              "4        [filmes, fotos, latão, palavra, apropriada, ve...\n",
              "                               ...                        \n",
              "49454    [média, votos, baixa, fato, funcionário, locad...\n",
              "49455    [enredo, algumas, reviravoltas, infelizes, ina...\n",
              "49456    [espantado, forma, filme, maioria, outros, méd...\n",
              "49457    [christmas, together, realmente, veio, antes, ...\n",
              "49458    [drama, romântico, classe, trabalhadora, diret...\n",
              "Name: text_pt_LIMPO_EMB, Length: 49459, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_embedding = df['text_pt_LIMPO_EMB'].progress_apply(lambda x: calcula_embedding(x)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48,
          "referenced_widgets": [
            "86ba03eb85b440028bdc1b304f786aab",
            "01d4b63812cd4a61beca2d14a92dbd1c",
            "b727db06d87d4d888472043d4df643d3",
            "9d3fb1f39cac4452837eaf518bc8a9c3",
            "a5b40eab76c647fabfba370778bc26c9",
            "aef04d4433c1414ab9002251798eda0b",
            "d3268643c19e4975bce5419f1cecf51d",
            "58e9243afc0a442db2f9a653a57b67fe",
            "8fb25a5009884a3b94e75884c9db7175",
            "2873c8c2cef648209bca9acf4ee95859",
            "cfd36b35d34f46139fb60be799239fd2"
          ]
        },
        "id": "MPv1-unXeqPm",
        "outputId": "f25a021e-a159-4d6f-d3c3-56e3799bb22f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86ba03eb85b440028bdc1b304f786aab",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/49459 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbZ6f-7WI5l-",
        "outputId": "5dfdd145-7f8b-4cb6-d3d4-0bc422825964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [0.14301138, 0.22025318, -0.047075942, -0.2170...\n",
              "1        [0.16303213, 0.22678684, -0.05451168, -0.20547...\n",
              "2        [0.21659917, 0.14430527, -0.0034280657, -0.197...\n",
              "3        [0.2596114, 0.13605723, -0.07343373, -0.208256...\n",
              "4        [0.22052252, 0.087914094, -0.06986406, -0.1659...\n",
              "                               ...                        \n",
              "49454    [0.16023268, 0.1474827, -0.08474423, -0.103290...\n",
              "49455    [0.17767419, 0.1423968, -0.081170976, -0.22615...\n",
              "49456    [0.18305564, 0.18313898, -0.062747374, -0.1887...\n",
              "49457    [0.18229564, 0.15024172, -0.08812309, -0.22163...\n",
              "49458    [0.26787597, 0.16923124, -0.06144687, -0.18159...\n",
              "Name: text_pt_LIMPO_EMB, Length: 49459, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqPJf0yLZZoQ"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_xhW7e2ZZoQ"
      },
      "source": [
        "### CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kpcc167FZZoR"
      },
      "source": [
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "14) Faça a divisão dados dados em treino e teste como no exemplo abaixo:\n",
        "\n",
        "```python\n",
        "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(X_bag, target,random_state=123)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3MeGchRZZoS"
      },
      "source": [
        "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(X_bag, target,random_state=123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0ggm8ZLZZoY"
      },
      "source": [
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "15) Treine com uma regressão logística"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJN8KMHiZZoa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ca14f7b-cfca-44d6-9fc4-5d708e9c8585"
      },
      "source": [
        "modelo_bow = LogisticRegression()\n",
        "modelo_bow.fit(X_train_bow,y_train_bow)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivlITfC2ZZof"
      },
      "source": [
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "16) Calcule as métricas de resultado utilizando método abaixo:\n",
        "\n",
        "```python\n",
        "print(classification_report(y_test_bow, y_pred))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predi = modelo_bow.predict(X_test_bow)"
      ],
      "metadata": {
        "id": "zTZZJg7FKo4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsfRxqjSZZog",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df6468e3-6723-4a97-8a22-0e8218c43877"
      },
      "source": [
        "y_predi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test_bow, y_predi))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DY7ii307LJTX",
        "outputId": "3212a1ac-5384-449a-d67b-f59faac5e46c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.87      0.88      6112\n",
            "           1       0.87      0.89      0.88      6253\n",
            "\n",
            "    accuracy                           0.88     12365\n",
            "   macro avg       0.88      0.88      0.88     12365\n",
            "weighted avg       0.88      0.88      0.88     12365\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiulNTGNZZoj"
      },
      "source": [
        "### Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6abN65iqZZok"
      },
      "source": [
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "17) Faça a divisão dados dados em treino e teste como no exemplo abaixo:\n",
        "\n",
        "Verifique o shape do X treino e X teste. Caso eles estejam com apenas uma dimensão, você precisa tranformá-los para duas dimensões, caso contrário ocorrerá erro no treinamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn57b04_ZZol"
      },
      "source": [
        "X_train_emb, X_test_emb, y_train_emb, y_test_emb = train_test_split(X_embedding.values,target,random_state=123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_emb = pd.DataFrame([x for x in X_train_emb])"
      ],
      "metadata": {
        "id": "OMz9HcCGM0FW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_emb = pd.DataFrame([x for x in X_test_emb])"
      ],
      "metadata": {
        "id": "Or6MG55kNRU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9BR0H7fZZop"
      },
      "source": [
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "18) Treine com uma regressão logística"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJI29fY2ZZoq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "702d020d-5c66-4df9-f837-69f81c57f334"
      },
      "source": [
        "modelo_bow = LogisticRegression()\n",
        "modelo_bow.fit(X_train_emb, y_train_emb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvIYI1lJZZow"
      },
      "source": [
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "19) Calcule as métricas de resultado utilizando método abaixo:\n",
        "\n",
        "```python\n",
        "print(classification_report(y_test_bow, y_pred))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predi = modelo_bow.predict(X_test_emb)"
      ],
      "metadata": {
        "id": "IUQL1HdSNcfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test_emb, y_predi))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5masICMANgKp",
        "outputId": "fabce5a3-b723-427e-b8af-1d01cd4f6c16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.77      0.77      6112\n",
            "           1       0.78      0.77      0.77      6253\n",
            "\n",
            "    accuracy                           0.77     12365\n",
            "   macro avg       0.77      0.77      0.77     12365\n",
            "weighted avg       0.77      0.77      0.77     12365\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClFB32whZZox"
      },
      "source": [
        "#### Calcule as métricas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-dRYhR_ZZoy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sp62Sb1ZZo1"
      },
      "source": [
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "20) Compare os resultados obtidos com o BagOfWords e com o Embedding. Explique os possíveis motivos desta diferença."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RShZ0680ZZo2"
      },
      "source": [
        "O problema e de análise sentimentos, a variável target é positivo ou negativo. O bag of words demarca a presença ou não das palavras dentro de um texto. Ou ele mapeia melhor as palavras negativas e positivas de um texto que o embedding. Para o problema de análise de sentimentos com a base de dados em questão foi melhor o Bag of word do que o embedding analisando a semântica do contexto. O embedding apesar de uma boa metodologia, foi utilizado tem 100 dimensões enquanto que o Bag of words tem 127000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-oH0GQfZZo3"
      },
      "source": [
        "# Análise de sentimentos\n",
        "\n",
        "O modelo que criamos anteriormente é para ilustrar como podemos realizar classificação de documentos.\n",
        "Quando a tarefa é sobre análise de sentimentos, temos duas opções: treinar nosso próprio modelo, como feito anteriormente ou utilizar uma das inúmeras ferramentas prontas.\n",
        "\n",
        "Vamos testar as seguintes ferramentas:\n",
        "\n",
        "- Vader\n",
        "- Textblob\n",
        "- Affin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilpNXE0cZZo3"
      },
      "source": [
        "Nesta atividade iremos utilizar as duas variáveis abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq0dLI9JZZo4"
      },
      "source": [
        "texto_neg = df.loc[0, \"text_en\"]\n",
        "texto_pos = df.loc[49431, \"text_en\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dB-FuBgZZo9"
      },
      "source": [
        "## Vader\n",
        "\n",
        "<b> Apenas Inglês </b>\n",
        "\n",
        "O VADER (Valence Aware Dictionary e sEntiment Reasoner) é uma ferramenta de análise de sentimentos baseada em regras e léxico, especificamente identifica os sentimentos expressos nas mídias sociais.\n",
        "\n",
        "- positive sentiment: compound score >= 0.05\n",
        "- neutral sentiment: (compound score > -0.05) e (compound score < 0.05)\n",
        "- negative sentiment: compound score <= -0.05\n",
        "\n",
        "Mais informações: https://github.com/cjhutto/vaderSentiment\n",
        "\n",
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "21) Aplique este método nas revisões ```texto_pos``` e ```texto_neg```.\n",
        "Para aplicar:\n",
        "\n",
        "```python\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "analyzer.polarity_scores(texto)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZE5KL-9ZZo9"
      },
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzsgloUpZZpB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b064106-e9b8-4fd3-c4a7-121093c9b501"
      },
      "source": [
        "analyzer = SentimentIntensityAnalyzer()\n",
        "analyzer.polarity_scores(texto_neg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'compound': 0.3958, 'neg': 0.126, 'neu': 0.76, 'pos': 0.114}"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer = SentimentIntensityAnalyzer()\n",
        "analyzer.polarity_scores(texto_pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FiOGlFIRGuV",
        "outputId": "774a3fa9-1b3d-4705-d01c-d9feb0e02ee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'compound': 0.9969, 'neg': 0.084, 'neu': 0.737, 'pos': 0.179}"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDrJTCfKZZpE"
      },
      "source": [
        "## TextBlob\n",
        "\n",
        "<b> Apenas inglês </b>\n",
        "\n",
        "https://www.presentslide.in/2019/08/sentiment-analysis-textblob-library.html\n",
        "\n",
        "<b> Atividade </b>\n",
        " \n",
        "22) Aplique este método nas revisões ```texto_pos``` e ```texto_neg```.\n",
        "Para aplicar:\n",
        "\n",
        "```python\n",
        "sentence=TextBlob(texto)\n",
        "sentence.sentiment\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9IvBg5sZZpE"
      },
      "source": [
        "from textblob import TextBlob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-BV6UkOZZpJ"
      },
      "source": [
        "sentence=TextBlob(texto_neg )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence.sentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HihrHghbRfJ0",
        "outputId": "6ae143e5-e94a-4f3d-96e6-2f17fdebae05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment(polarity=0.06385964912280702, subjectivity=0.5629824561403508)"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence=TextBlob(texto_pos)"
      ],
      "metadata": {
        "id": "-Ce75UKPRhOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence.sentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-83rsxYRnRD",
        "outputId": "eaec41ee-df67-400e-942f-61fe422ff5bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment(polarity=0.190819118692253, subjectivity=0.6026226012793177)"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwk7dHuFZZpO"
      },
      "source": [
        "## Afinn\n",
        "\n",
        "- Valor maior que 0 indica sentimento positivo\n",
        "- Valor menor que 0 indica sentimento negativo\n",
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "23) Aplique este método nas revisões ```texto_pos``` e ```texto_neg```.\n",
        "Para aplicar:\n",
        "\n",
        "```python\n",
        "afinn = Afinn()\n",
        "afinn.score(texto)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2FS5AUsZZpP"
      },
      "source": [
        "from afinn import Afinn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF8E0CjzZZpX"
      },
      "source": [
        "afinn = Afinn()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "afinn.score(texto_neg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5wPb6HURv1u",
        "outputId": "c595836d-0cab-4e36-ef3a-47ab8dba407c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.0"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "afinn.score(texto_pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPLnJXAKR0VL",
        "outputId": "c393a9ce-d532-4648-a4f5-5c0bff32d7cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55.0"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkhkDVIxZZpa"
      },
      "source": [
        "<b> Atividade </b>\n",
        "\n",
        "24) Para você, qual ferramenta teve melhor comportamento?  Justifique com exemplos."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O sentimento de Vader pois retorna a probabilidade de uma determinada frase de entrada ser positiva, negativa e neutra.\n",
        "\n",
        "Por exemplo:\n",
        "\n",
        "“O filme foi incrível!”\n",
        "Positivo: 99%\n",
        "Negativo: 1%\n",
        "Neutro: 0%"
      ],
      "metadata": {
        "id": "fU-4p4-6ThpU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWImUeS0ZZpb"
      },
      "source": [
        "# Dica:\n",
        "## Quando for trabalhar com um dataset em inglês, a biblioteca Spacy facilita!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gONqxhviZZpc"
      },
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hj3KE97ZZph"
      },
      "source": [
        "import spacy\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW0GLnhVZZpn"
      },
      "source": [
        "O scpay forne um pacote que já tem série de modelos já treinados em NLP. Inclusive para os embeddings em inglês.\n",
        "\n",
        "Para mais informações vá em:\n",
        "\n",
        "https://spacy.io/models/en#en_core_web_md\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v02Lid1QZZpo"
      },
      "source": [
        "Com o método abaixo carregamos um dos modelos do spacy:\n",
        "\n",
        "```python\n",
        "nlp = spacy.load('en_core_web_md')\n",
        "```\n",
        "\n",
        "Para aplicar o modelo, basta passar o texto para o modelo carregado anteriormente:\n",
        "\n",
        "```python\n",
        "doc = nlp(\"This is some text that I am processing with Spacy\")\n",
        "```\n",
        "\n",
        "Carregue o modelo e imprima doc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjRx4bZxZZpo"
      },
      "source": [
        "nlp = spacy.load('en_core_web_md')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDsD2THwZZps"
      },
      "source": [
        "doc = nlp(\"This is some text that I am processing with Spacy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDWkp1tfZZpy"
      },
      "source": [
        "doc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuqCJaIMZZp3"
      },
      "source": [
        "Ao aplicar o modelo carregado a variável <b> doc </b> já possui os embeddings de cada uma das palavras e o embedding da frase, que é a média de todos vetores de todas palavras.\n",
        "\n",
        "```python\n",
        "#vetor da primeira palavra\n",
        "doc[0].vector\n",
        "#vetor agregado pela média - embedding do documento\n",
        "doc.vector\n",
        "```\n",
        "O código abaixo mostra que a média de uma posição em específico dos embeddings de todas as palavras e a posição do embedding do documento possuem o mesmo valor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r426C5mvZZp4"
      },
      "source": [
        "def calcula_media_posicao(x):\n",
        "    soma = 0\n",
        "    vector = []\n",
        "    for i in range(0,len(doc)):\n",
        "        vector.append(doc[i].vector)    \n",
        "    \n",
        "    for v in vector:\n",
        "        soma += v[x]\n",
        "    return soma/len(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "969rVBBYZZp8"
      },
      "source": [
        "round(calcula_media_posicao(10),6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmkeEtyQZZqB"
      },
      "source": [
        "round(doc.vector[10], 6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjZQ_jAMZZqF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}